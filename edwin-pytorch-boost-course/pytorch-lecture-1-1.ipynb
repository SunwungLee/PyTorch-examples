{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic notation\n",
    "## 2d tensor \n",
    "# |t| = (batch, dim) e.g. 64 x 256\n",
    "\n",
    "## 3d tensor - vision\n",
    "# |t| = (batch, width, height) --> a number of images\n",
    "# pytorch -- (세로, 가로, 깊이) sequence\n",
    "\n",
    "## 3d tensor - NLP(natural language processing)\n",
    "# |t| = (batch, length, dim)\n",
    "# 단면이 하나의 문장, batch size만큼 쌓여있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n",
      "Rank of t:  1\n",
      "Shape of t:  (7,)\n",
      "t[0] t[1] t[-1] =  0.0 1.0 6.0\n",
      "t[2:5] t[4:-1] =  [2. 3. 4.] [4. 5.]\n",
      "t[:2] t[3:] =  [0. 1.] [3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# NumPy Review - 1D Array with NumPy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "print(t)\n",
    "print('Rank of t: ', t.ndim) # 몇개의 차원\n",
    "print('Shape of t: ', t.shape) # 하나의 차원은 어떻게 있니\n",
    "print('t[0] t[1] t[-1] = ', t[0],t[1],t[-1]) # -1인덱스는 맨 마지막에서 첫번쨰\n",
    "print('t[2:5] t[4:-1] = ', t[2:5], t[4:-1])\n",
    "print('t[:2] t[3:] = ', t[:2], t[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.]\n",
      " [ 4.  5.  6.]\n",
      " [ 7.  8.  9.]\n",
      " [10. 11. 12.]]\n",
      "2\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "# NumPy Review - 2D Array with NumPy\n",
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "print(t)\n",
    "print(t.ndim)  # rank\n",
    "print(t.shape) # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch is just like NumPy - 1D\n",
    "t = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft)\n",
    "print(ft.dim())  # rank\n",
    "print(ft.shape)  # shape\n",
    "print(ft.size()) # shape\n",
    "print(ft[0], ft[1], ft[-1]) # Element\n",
    "print(ft[2:5], ft[4:-1])    # Slicing\n",
    "print(ft[:2], ft[3:])       # Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch is just like NumPy - 2D\n",
    "t = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.], [10., 11., 12.]])\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft)\n",
    "print(ft.dim())  # rank\n",
    "print(ft.size()) # shape\n",
    "print(ft[:, 1])\n",
    "print(ft[:, 1].size())\n",
    "print(ft[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 5.]])\n",
      "---------\n",
      "tensor([[4., 5.]])\n",
      "---------\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "## Broadcasting\n",
    "# Same shape\n",
    "m1 = torch.FloatTensor([[3, 3]])\n",
    "m2 = torch.FloatTensor([[2, 2]])\n",
    "print(m1 + m2)\n",
    "print('---------')\n",
    "# Vector + scalar\n",
    "m1 = torch.FloatTensor([[1, 2]])\n",
    "m2 = torch.FloatTensor([3]) # 3 -> [[3, 3]] -- 크기를 자동으로 바꿔서 연산 수행.\n",
    "print(m1 + m2)\n",
    "print('---------')\n",
    "# 2 x 1 Vector + 1 x 2 Vector\n",
    "m1 = torch.FloatTensor([[1, 2]]) # 2x2 로 변환해서 두개를 덧셈 연산함.\n",
    "m2 = torch.FloatTensor([[3], [4]])\n",
    "print(m1 + m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "---------\n",
      "Shape of Matrix 1:  torch.Size([2, 2])\n",
      "Shape of Matrix 2:  torch.Size([2, 1])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "##'Mul vs Matmul'\n",
    "# Deep learning은 행렬 곱을 많이 사용함.\n",
    "# \n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1.matmul(m2)) # 2 x 1\n",
    "print('---------')\n",
    "m1 = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "m2 = torch.FloatTensor([[1], [2]])\n",
    "print('Shape of Matrix 1: ', m1.shape) # 2 x 2\n",
    "print('Shape of Matrix 2: ', m2.shape) # 2 x 1\n",
    "print(m1 * m2) # 2 x 2\n",
    "print(m1.mul(m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n",
      "Can only calculate the mean of floating types. Got Long instead.\n",
      "---------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "# Mean\n",
    "t = torch.FloatTensor([1, 2])\n",
    "print(t.mean())\n",
    "\n",
    "# Can't use mean() on integers\n",
    "t = torch.LongTensor([1, 2])\n",
    "try:\n",
    "    print(t.mean())\n",
    "except Exception as exc:\n",
    "    print(exc)\n",
    "    \n",
    "print('---------')\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "\n",
    "print(t.mean()) # 전체 평균\n",
    "print(t.mean(dim=0)) # \n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "# Sum\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "\n",
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "---------\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max:  tensor([3., 4.])\n",
      "Argmax:  tensor([1, 1])\n",
      "---------\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "torch.return_types.max(\n",
      "values=tensor([2., 4.]),\n",
      "indices=tensor([1, 1]))\n"
     ]
    }
   ],
   "source": [
    "# Max and Argmax\n",
    "t = torch.FloatTensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "print('---------')\n",
    "print(t.max()) # Returns one value: max\n",
    "print(t.max(dim=0)) # Returns two values: max and argmax\n",
    "print('Max: ', t.max(dim=0)[0]) # value\n",
    "print('Argmax: ', t.max(dim=0)[1]) # index \n",
    "print('---------')\n",
    "print(t.max(dim=1))\n",
    "print(t.max(dim=-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
